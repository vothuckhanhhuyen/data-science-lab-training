{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Session1.3-Tfidf.ipynb","provenance":[],"authorship_tag":"ABX9TyMaSt3wh8PIlbZObfm+A5XR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"c_fHLa2C2AsP"},"source":["# **III. TIỀN XỬ LÝ DỮ LIỆU**"]},{"cell_type":"markdown","metadata":{"id":"RPGoSAEW1uvI"},"source":["**1. TF-IDF**\n","\n","- Biểu diễn TF-IDF đối với 1 văn bản d trong một tập văn bản D (corpus):\n","\n","$r_d = [tf-idf(w_1, d, D), tf-idf(w_2, d, D), ..., tf-idf(w_{|V|}, d, D)]$\n","\n","với, $r_d \\in R^{|V|}$ là một vector $|V|$ chiều và $V = {w_i}$ là từ điển (tập các từ xuất hiện trong $D$) đối với $D$\n","\n","- Trong đó:\n","\n","$tf-idf(w_i, d, D) = tf(w_i, d) * idf(w_i, D)$\n","\n","với,\n","\n","$tf(w_i, d) = \\dfrac{f(w_i, d)}{max(f(w_j, d): w_j \\in V)}$\n","\n","$idf(w_i, D) = log_{10}^{\\dfrac{|D|}{|d' \\in D: w_i \\in d'|}}$\n","\n","- Xác định từ điển V:\n","\n","  - Với mỗi văn bản $d$ trong $D$:\n","    - Tách d thành các từ theo punctuations ta thu được $W_d$\n","    - Loại bỏ từ dừng - stop words khỏi $W_d$\n","    - Đưa các từ về dạng gốc(stemming)\n","    - Ta thu được $W_d$\n","  - Cuối cùng:\n","    $V = $ giao của $W_d$ với $d \\in D$"]},{"cell_type":"markdown","metadata":{"id":"zM4BTguw1uvJ"},"source":["**Simple example - not in slide**"]},{"cell_type":"code","metadata":{"id":"7VvCOj2n1uvJ"},"source":["import pandas as pd\n","import sklearn as sk\n","import math"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8ngBRkJg1uvK","executionInfo":{"status":"ok","timestamp":1618982310732,"user_tz":-420,"elapsed":1654,"user":{"displayName":"Vo Thuc Khanh Huyen FX06758","photoUrl":"","userId":"10987621998736532516"}},"outputId":"3667a3a6-7a1d-492a-a8e3-54e22ffcccf5"},"source":["# Create data\n","\n","first_sentence = \"Data Science is the sexiest job of the 21st century\"\n","second_sentence = \"machine learning is the key for data science\"\n","\n","first_sentence = first_sentence.lower()\n","second_sentence = second_sentence.lower()\n","\n","first_sentence = first_sentence.split(\" \")\n","second_sentence = second_sentence.split(\" \")\n","total = set(first_sentence).union(set(second_sentence))\n","\n","print(first_sentence)\n","print(second_sentence)\n","print(total)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['data', 'science', 'is', 'the', 'sexiest', 'job', 'of', 'the', '21st', 'century']\n","['machine', 'learning', 'is', 'the', 'key', 'for', 'data', 'science']\n","{'of', 'data', 'science', 'job', 'century', 'machine', 'key', 'is', 'for', '21st', 'learning', 'sexiest', 'the'}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vCAnF6TZ1uvL","executionInfo":{"status":"ok","timestamp":1618982311829,"user_tz":-420,"elapsed":2740,"user":{"displayName":"Vo Thuc Khanh Huyen FX06758","photoUrl":"","userId":"10987621998736532516"}},"outputId":"7125b705-c179-43eb-ed63-1416680922f6"},"source":["# Filter sentence by stopwords\n","\n","import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","stop_words = set(stopwords.words('english'))\n","\n","ft_first_sentence = [w for w in first_sentence if w not in stop_words]\n","ft_second_sentence = [w for w in second_sentence if w not in stop_words]\n","ft_total = set(ft_first_sentence).union(set(ft_second_sentence))\n","\n","print(ft_first_sentence)\n","print(ft_second_sentence)\n","print(ft_total)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","['data', 'science', 'sexiest', 'job', '21st', 'century']\n","['machine', 'learning', 'key', 'data', 'science']\n","{'data', 'science', 'job', 'century', 'machine', 'key', '21st', 'learning', 'sexiest'}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":111},"id":"OrfQYypJ1uvM","executionInfo":{"status":"ok","timestamp":1618982311836,"user_tz":-420,"elapsed":2728,"user":{"displayName":"Vo Thuc Khanh Huyen FX06758","photoUrl":"","userId":"10987621998736532516"}},"outputId":"e39886ec-0354-455f-d200-f298098f92a5"},"source":["# Create DataFrame\n","\n","wordDictA = dict.fromkeys(ft_total, 0) \n","wordDictB = dict.fromkeys(ft_total, 0)\n","\n","for word in ft_first_sentence:\n","    wordDictA[word] += 1\n","for word in ft_second_sentence:\n","    wordDictB[word] += 1\n","\n","data = pd.DataFrame([wordDictA, wordDictB])\n","data"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>data</th>\n","      <th>science</th>\n","      <th>job</th>\n","      <th>century</th>\n","      <th>machine</th>\n","      <th>key</th>\n","      <th>21st</th>\n","      <th>learning</th>\n","      <th>sexiest</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   data  science  job  century  machine  key  21st  learning  sexiest\n","0     1        1    1        1        0    0     1         0        1\n","1     1        1    0        0        1    1     0         1        0"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":111},"id":"ZLwvDFHA1uvM","executionInfo":{"status":"ok","timestamp":1618982311838,"user_tz":-420,"elapsed":2710,"user":{"displayName":"Vo Thuc Khanh Huyen FX06758","photoUrl":"","userId":"10987621998736532516"}},"outputId":"69f3a97f-57ae-443b-91c5-34420193a1ad"},"source":["# tf section\n","\n","def computeTF(wordDict):\n","    tfDict = {}\n","    for word, count in wordDict.items():\n","        tfDict[word] = count / max(wordDict.values())\n","    return tfDict\n","\n","tf_A = computeTF(wordDictA)\n","tf_B = computeTF(wordDictB)\n","\n","tf = pd.DataFrame([tf_A, tf_B])\n","tf"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>data</th>\n","      <th>science</th>\n","      <th>job</th>\n","      <th>century</th>\n","      <th>machine</th>\n","      <th>key</th>\n","      <th>21st</th>\n","      <th>learning</th>\n","      <th>sexiest</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   data  science  job  century  machine  key  21st  learning  sexiest\n","0   1.0      1.0  1.0      1.0      0.0  0.0   1.0       0.0      1.0\n","1   1.0      1.0  0.0      0.0      1.0  1.0   0.0       1.0      0.0"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L8msvNkf1uvN","executionInfo":{"status":"ok","timestamp":1618982311843,"user_tz":-420,"elapsed":2706,"user":{"displayName":"Vo Thuc Khanh Huyen FX06758","photoUrl":"","userId":"10987621998736532516"}},"outputId":"e2b3f022-404b-41d1-b05d-512201d73f7d"},"source":["# idf section\n","\n","def computeIDF(data):\n","  N = data.shape[0] \n","  idfDict = dict.fromkeys(data.columns, 0)\n","  for word, val in idfDict.items():\n","    val = (data[word] != 0).sum()\n","    idfDict[word] = math.log10(N / float(val)) # not +1 because < 0\n","  return idfDict\n","\n","idf = computeIDF(data)\n","idf"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'21st': 0.3010299956639812,\n"," 'century': 0.3010299956639812,\n"," 'data': 0.0,\n"," 'job': 0.3010299956639812,\n"," 'key': 0.3010299956639812,\n"," 'learning': 0.3010299956639812,\n"," 'machine': 0.3010299956639812,\n"," 'science': 0.0,\n"," 'sexiest': 0.3010299956639812}"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":111},"id":"_Uj5XanL1uvN","executionInfo":{"status":"ok","timestamp":1618982311844,"user_tz":-420,"elapsed":2696,"user":{"displayName":"Vo Thuc Khanh Huyen FX06758","photoUrl":"","userId":"10987621998736532516"}},"outputId":"bf408ec2-8eee-4e06-cc99-5d233dc2a1b4"},"source":["# tf-idf section\n","\n","def computeTFIDF(tfWordDict, idfs):\n","  tfidf = {}\n","  for word, val in tfWordDict.items():\n","    tfidf[word] = val * idfs[word]\n","  return tfidf\n","\n","idfs = computeIDF(data)\n","tfidf_A = computeTFIDF(tf_A, idfs)\n","tfidf_B = computeTFIDF(tf_B, idfs)\n","\n","tfidf = pd.DataFrame([tfidf_A, tfidf_B])\n","tfidf"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>data</th>\n","      <th>science</th>\n","      <th>job</th>\n","      <th>century</th>\n","      <th>machine</th>\n","      <th>key</th>\n","      <th>21st</th>\n","      <th>learning</th>\n","      <th>sexiest</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.30103</td>\n","      <td>0.30103</td>\n","      <td>0.00000</td>\n","      <td>0.00000</td>\n","      <td>0.30103</td>\n","      <td>0.00000</td>\n","      <td>0.30103</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.00000</td>\n","      <td>0.00000</td>\n","      <td>0.30103</td>\n","      <td>0.30103</td>\n","      <td>0.00000</td>\n","      <td>0.30103</td>\n","      <td>0.00000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   data  science      job  century  ...      key     21st  learning  sexiest\n","0   0.0      0.0  0.30103  0.30103  ...  0.00000  0.30103   0.00000  0.30103\n","1   0.0      0.0  0.00000  0.00000  ...  0.30103  0.00000   0.30103  0.00000\n","\n","[2 rows x 9 columns]"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xxpcrDvL1uvO","executionInfo":{"status":"ok","timestamp":1618982311845,"user_tz":-420,"elapsed":2686,"user":{"displayName":"Vo Thuc Khanh Huyen FX06758","photoUrl":"","userId":"10987621998736532516"}},"outputId":"c7e7c6fc-f288-4c47-b40d-15e8881d4bde"},"source":["# Short step using sklearn\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","vectorize = TfidfVectorizer(stop_words='english')\n","\n","first_sentence = \"Data Science is the sexiest job of the 21st century\"\n","second_sentence = \"machine learning is the key for data science\"\n","\n","response = vectorize.fit_transform([first_sentence, second_sentence])\n","\n","print(response)\n","\n","# (x, y), x is data[x], y is in vectorize.get_feature_names()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["  (0, 1)\t0.4466561618018052\n","  (0, 0)\t0.4466561618018052\n","  (0, 3)\t0.4466561618018052\n","  (0, 8)\t0.4466561618018052\n","  (0, 7)\t0.31779953783628945\n","  (0, 2)\t0.31779953783628945\n","  (1, 4)\t0.4992213265230509\n","  (1, 5)\t0.4992213265230509\n","  (1, 6)\t0.4992213265230509\n","  (1, 7)\t0.35520008546852583\n","  (1, 2)\t0.35520008546852583\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pRAC7Xdv1uvO"},"source":["**Session example**"]}]}